{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/hshapour/.pyenv/versions/3.10.12/envs/pytorch/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda115.so\n",
      "CUDA SETUP: CUDA runtime path found: /usr/lib/x86_64-linux-gnu/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 115\n",
      "CUDA SETUP: Loading binary /home/hshapour/.pyenv/versions/3.10.12/envs/pytorch/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda115.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Llama tokenizer thingy\n",
      "pre-trained model's BOS EOS and PAD token id: 1 2 1  => It should be 1 2 None\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "# model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "cutoff_len = 4096\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "device_map = {\"\": 0}\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map,\n",
    "    # cache_dir = \"/dev/shm/hassan/.cahce/\"\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "if \"Llama-2\" in model_name or \"Mistral\" in model_name:\n",
    "    print(\"Doing Llama tokenizer thingy\")\n",
    "    # tokenizer.pad_token_id = tokenizer.bos_token_id\n",
    "    tokenizer.pad_token = tokenizer.bos_token\n",
    "\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "bos = tokenizer.bos_token_id\n",
    "eos = tokenizer.eos_token_id\n",
    "pad = tokenizer.pad_token_id\n",
    "print(\"pre-trained model's BOS EOS and PAD token id:\",bos,eos,pad,\" => It should be 1 2 None\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to find '/home/hshapour/llm-benchmarks/GLUE/multirc-data/2_shot_examples_small.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# fname_json = f\"mmlu-data/ex_no_space.json\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m n_shot \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m d1 \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39;49m\u001b[39mjson\u001b[39;49m\u001b[39m\"\u001b[39;49m, data_files\u001b[39m=\u001b[39;49m{\n\u001b[1;32m      4\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mdev\u001b[39;49m\u001b[39m'\u001b[39;49m : \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmultirc-data/\u001b[39;49m\u001b[39m{\u001b[39;49;00mn_shot\u001b[39m}\u001b[39;49;00m\u001b[39m_shot_examples_small.json\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      5\u001b[0m     })\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(d1[\u001b[39m'\u001b[39m\u001b[39mdev\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m2\u001b[39m][\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/pytorch/lib/python3.10/site-packages/datasets/load.py:2128\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2123\u001b[0m verification_mode \u001b[39m=\u001b[39m VerificationMode(\n\u001b[1;32m   2124\u001b[0m     (verification_mode \u001b[39mor\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mBASIC_CHECKS) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m save_infos \u001b[39melse\u001b[39;00m VerificationMode\u001b[39m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2125\u001b[0m )\n\u001b[1;32m   2127\u001b[0m \u001b[39m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2128\u001b[0m builder_instance \u001b[39m=\u001b[39m load_dataset_builder(\n\u001b[1;32m   2129\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m   2130\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m   2131\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   2132\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   2133\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   2134\u001b[0m     features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2135\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   2136\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   2137\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   2138\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   2139\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2140\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig_kwargs,\n\u001b[1;32m   2141\u001b[0m )\n\u001b[1;32m   2143\u001b[0m \u001b[39m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2144\u001b[0m \u001b[39mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/pytorch/lib/python3.10/site-packages/datasets/load.py:1814\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1812\u001b[0m     download_config \u001b[39m=\u001b[39m download_config\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m download_config \u001b[39melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1813\u001b[0m     download_config\u001b[39m.\u001b[39mstorage_options\u001b[39m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1814\u001b[0m dataset_module \u001b[39m=\u001b[39m dataset_module_factory(\n\u001b[1;32m   1815\u001b[0m     path,\n\u001b[1;32m   1816\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m   1817\u001b[0m     download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1818\u001b[0m     download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[1;32m   1819\u001b[0m     data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1820\u001b[0m     data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1821\u001b[0m )\n\u001b[1;32m   1822\u001b[0m \u001b[39m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1823\u001b[0m builder_kwargs \u001b[39m=\u001b[39m dataset_module\u001b[39m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/pytorch/lib/python3.10/site-packages/datasets/load.py:1429\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[39m# We have several ways to get a dataset builder:\u001b[39;00m\n\u001b[1;32m   1407\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   1408\u001b[0m \u001b[39m# - if path is the name of a packaged dataset module\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \n\u001b[1;32m   1421\u001b[0m \u001b[39m# Try packaged\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39min\u001b[39;00m _PACKAGED_DATASETS_MODULES:\n\u001b[1;32m   1423\u001b[0m     \u001b[39mreturn\u001b[39;00m PackagedDatasetModuleFactory(\n\u001b[1;32m   1424\u001b[0m         path,\n\u001b[1;32m   1425\u001b[0m         data_dir\u001b[39m=\u001b[39;49mdata_dir,\n\u001b[1;32m   1426\u001b[0m         data_files\u001b[39m=\u001b[39;49mdata_files,\n\u001b[1;32m   1427\u001b[0m         download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m   1428\u001b[0m         download_mode\u001b[39m=\u001b[39;49mdownload_mode,\n\u001b[0;32m-> 1429\u001b[0m     )\u001b[39m.\u001b[39;49mget_module()\n\u001b[1;32m   1430\u001b[0m \u001b[39m# Try locally\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m \u001b[39melif\u001b[39;00m path\u001b[39m.\u001b[39mendswith(filename):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/pytorch/lib/python3.10/site-packages/datasets/load.py:957\u001b[0m, in \u001b[0;36mPackagedDatasetModuleFactory.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    955\u001b[0m base_path \u001b[39m=\u001b[39m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_dir \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mexpanduser()\u001b[39m.\u001b[39mresolve()\u001b[39m.\u001b[39mas_posix()\n\u001b[1;32m    956\u001b[0m patterns \u001b[39m=\u001b[39m sanitize_patterns(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m get_data_patterns(base_path)\n\u001b[0;32m--> 957\u001b[0m data_files \u001b[39m=\u001b[39m DataFilesDict\u001b[39m.\u001b[39;49mfrom_patterns(\n\u001b[1;32m    958\u001b[0m     patterns,\n\u001b[1;32m    959\u001b[0m     download_config\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload_config,\n\u001b[1;32m    960\u001b[0m     base_path\u001b[39m=\u001b[39;49mbase_path,\n\u001b[1;32m    961\u001b[0m )\n\u001b[1;32m    962\u001b[0m supports_metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m _MODULE_SUPPORTS_METADATA\n\u001b[1;32m    963\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m supports_metadata \u001b[39mand\u001b[39;00m patterns \u001b[39m!=\u001b[39m DEFAULT_PATTERNS_ALL:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/pytorch/lib/python3.10/site-packages/datasets/data_files.py:686\u001b[0m, in \u001b[0;36mDataFilesDict.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    683\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m()\n\u001b[1;32m    684\u001b[0m \u001b[39mfor\u001b[39;00m key, patterns_for_key \u001b[39min\u001b[39;00m patterns\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    685\u001b[0m     out[key] \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 686\u001b[0m         DataFilesList\u001b[39m.\u001b[39;49mfrom_patterns(\n\u001b[1;32m    687\u001b[0m             patterns_for_key,\n\u001b[1;32m    688\u001b[0m             base_path\u001b[39m=\u001b[39;49mbase_path,\n\u001b[1;32m    689\u001b[0m             allowed_extensions\u001b[39m=\u001b[39;49mallowed_extensions,\n\u001b[1;32m    690\u001b[0m             download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m    691\u001b[0m         )\n\u001b[1;32m    692\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(patterns_for_key, DataFilesList)\n\u001b[1;32m    693\u001b[0m         \u001b[39melse\u001b[39;00m patterns_for_key\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/pytorch/lib/python3.10/site-packages/datasets/data_files.py:591\u001b[0m, in \u001b[0;36mDataFilesList.from_patterns\u001b[0;34m(cls, patterns, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[39mfor\u001b[39;00m pattern \u001b[39min\u001b[39;00m patterns:\n\u001b[1;32m    589\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m         data_files\u001b[39m.\u001b[39mextend(\n\u001b[0;32m--> 591\u001b[0m             resolve_pattern(\n\u001b[1;32m    592\u001b[0m                 pattern,\n\u001b[1;32m    593\u001b[0m                 base_path\u001b[39m=\u001b[39;49mbase_path,\n\u001b[1;32m    594\u001b[0m                 allowed_extensions\u001b[39m=\u001b[39;49mallowed_extensions,\n\u001b[1;32m    595\u001b[0m                 download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[1;32m    596\u001b[0m             )\n\u001b[1;32m    597\u001b[0m         )\n\u001b[1;32m    598\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    599\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m has_magic(pattern):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/pytorch/lib/python3.10/site-packages/datasets/data_files.py:380\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[39mif\u001b[39;00m allowed_extensions \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m         error_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m with any supported extension \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(allowed_extensions)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 380\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(error_msg)\n\u001b[1;32m    381\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to find '/home/hshapour/llm-benchmarks/GLUE/multirc-data/2_shot_examples_small.json'"
     ]
    }
   ],
   "source": [
    "# fname_json = f\"mmlu-data/ex_no_space.json\"\n",
    "n_shot = 2\n",
    "d1 = load_dataset(\"json\", data_files={\n",
    "        'dev' : f\"multirc-data/{n_shot}_shot_examples_small.json\"\n",
    "    })\n",
    "print(d1['dev'][2]['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch tensor elapsed time:  0.4870028495788574  sec\n"
     ]
    }
   ],
   "source": [
    "number_of_examples = 10\n",
    "\n",
    "################################################\n",
    "# method 2: generate tensor of examples\n",
    "ex1 = d1['dev'][:number_of_examples]['input']\n",
    "input_ids = tokenizer(ex1, padding=True, return_tensors='pt').input_ids\n",
    "input_ids = input_ids.to(device=0)\n",
    "\n",
    "tic = time.time()\n",
    "with torch.no_grad():\n",
    "    output = model(input_ids)\n",
    "    answers_2 = output.logits.squeeze()\n",
    "    if len(ex1) == 1:\n",
    "        answers_2 = answers_2.unsqueeze(0)\n",
    "\n",
    "toc = time.time()\n",
    "dt_2 = toc-tic\n",
    "\n",
    "print(\"Pytorch tensor elapsed time: \", dt_2, \" sec\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['True', 'False', '▁True', 'No']\n"
     ]
    }
   ],
   "source": [
    "top_k = 4\n",
    "\n",
    "ones = torch.ones_like(input_ids)\n",
    "last_token = input_ids == ones\n",
    "row_indices = torch.arange(input_ids.size(0))\n",
    "last_token = (torch.sum(last_token, dim = 1) + 1) * (-1)\n",
    "# if \"Llama-2\" in model_name:\n",
    "if \"Llama-2\" in model_name or \"Mistral\" in model_name:\n",
    "    last_token+=1\n",
    "_, top_choices2 = torch.topk(answers_2[row_indices,last_token,:], top_k)\n",
    "# _, top_choices2 = torch.topk(answers_2[row_indices,label_non_zero_id,:], top_k)\n",
    "print(tokenizer.convert_ids_to_tokens(top_choices2[0,:]))\n",
    "\n",
    "# print(torch.all(top_choices1[:,0] ==  top_choices2[:,0].cpu()))\n",
    "# print(top_choices1[:,0] ==  top_choices2[:,0].cpu())\n",
    "# print(tokenizer.decode(top_choices1[:,0]))\n",
    "# print(top_choices2[:,0].cpu())\n",
    "# print((top_choices3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [5852], 'attention_mask': [1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5574, 8824, 5852, 3782], device='cuda:0')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer(\"True\",add_special_tokens=False))\n",
    "top_choices2[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁choice', '1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.convert_ids_to_tokens(5852)\n",
    "toks = tokenizer('choice1').input_ids[1:]\n",
    "tokenizer.convert_ids_to_tokens(toks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
